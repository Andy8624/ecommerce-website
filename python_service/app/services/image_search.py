import os
import numpy as np
import faiss
import torch
import logging
import base64
import httpx
import asyncio
import json
from PIL import Image
from io import BytesIO
from transformers import AutoModel, AutoImageProcessor

logging.basicConfig(level=logging.DEBUG)

class ImageSearchService:
    def __init__(self):
        # Kh·ªüi t·∫°o t√™n m√¥ h√¨nh
        self.model_name = "google/siglip2-base-patch16-224"
        
        # T·∫£i m√¥ h√¨nh v√† processor
        self.model = AutoModel.from_pretrained(self.model_name, torch_dtype=torch.float32).eval()
        self.processor = AutoImageProcessor.from_pretrained(self.model_name, use_fast=True)
        
        # T·∫°o ch·ªâ m·ª•c FAISS
        # self.index = self._build_index()

    def _extract_features(self, image: Image.Image) -> np.ndarray:
        """Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng c·ªßa h√¨nh ·∫£nh, tr·∫£ v·ªÅ vector 768 chi·ªÅu"""
        inputs = self.processor(images=image, return_tensors="pt")
        with torch.no_grad():
            features = self.model.get_image_features(inputs.pixel_values)
        vector = features.cpu().numpy().flatten()
        assert vector.shape[0] == 768, f"Vector ph·∫£i c√≥ 768 chi·ªÅu, nh∆∞ng nh·∫≠n {vector.shape[0]}."
        # logging.debug("Vector {}", vector)
        return vector

    # HAM NAY KHONG SU DUNG (CHI DE TEST MO HINH)
    async def search_similar_images(self, image_content: bytes):
        """T√¨m t·∫•t c·∫£ ·∫£nh c√≥ kho·∫£ng c√°ch < 150 t·ª´ ch·ªâ m·ª•c FAISS"""
        query_image = Image.open(BytesIO(image_content)).convert("RGB")
        query_vector = self._extract_features(query_image)

        # T√¨m ki·∫øm v·ªõi s·ªë l∆∞·ª£ng t·ªëi ƒëa (n·∫øu d·ªØ li·ªáu l·ªõn c√≥ th·ªÉ d√πng k = 1000 ho·∫∑c l·ªõn h∆°n)
        D, I = self.index.search(np.array([query_vector]), k=50)

        product_images_dir = "app/assets/product_images"
        image_files = os.listdir(product_images_dir)
        
        # Ch·ªâ l·∫•y ·∫£nh c√≥ kho·∫£ng c√°ch < 100
        results = [
            {"image_path": os.path.join(product_images_dir, image_files[I[0][i]]), "distance": float(D[0][i])}
            for i in range(len(I[0])) if D[0][i] < 100 and I[0][i] != -1
        ]

        logging.debug(f"T√¨m th·∫•y {len(results)} h√¨nh ·∫£nh t∆∞∆°ng t·ª± v·ªõi kho·∫£ng c√°ch < 100.")
        return results

    def calculate_distance(self, vector1: np.ndarray, vector2: np.ndarray) -> float:
        """T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa hai vector ƒë·∫∑c tr∆∞ng"""
        assert vector1.shape == vector2.shape, "Hai vector ph·∫£i c√≥ c√πng k√≠ch th∆∞·ªõc."
        distance = np.linalg.norm(vector1 - vector2)  # T√≠nh L2 Distance (Euclidean Distance)
        logging.debug(f"Kho·∫£ng c√°ch gi·ªØa hai ·∫£nh: {distance}")
        return distance

    def base64_to_floats(self, base64_str):
        """Gi·∫£i m√£ base64 v√† chuy·ªÉn th√†nh m·∫£ng s·ªë th·ª±c"""
        try:
            decoded = base64.b64decode(base64_str)
            float_array = np.frombuffer(decoded, dtype=np.float32)
            return float_array
        except Exception as e:
            raise ValueError(f"L·ªói chuy·ªÉn ƒë·ªïi base64: {str(e)}")
        
    async def search_similar_products_api(self, image_content: bytes):
        """T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª± d·ª±a tr√™n ·∫£nh ng∆∞·ªùi d√πng t·∫£i l√™n, s·ª≠ d·ª•ng API (httpx)."""
        try:
            query_image = Image.open(BytesIO(image_content)).convert("RGB")
            query_vector = self._extract_features(query_image)
        except Exception as e:
            logging.error(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh t·∫£i l√™n: {e}")
            return []

        api_url = "http://host.docker.internal:8080/api/v1/image-tools"
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(api_url)
                response.raise_for_status()
                image_data = response.json()

                if not isinstance(image_data, dict) or "data" not in image_data or not isinstance(image_data["data"], list):
                    logging.warning("‚ö†Ô∏è API tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá!")
                    return []
            except httpx.HTTPStatusError as http_err:
                logging.error(f"‚ùå L·ªói HTTP t·ª´ API: {http_err.response.status_code}")
                return []
            except Exception as e:
                logging.error(f"‚ùå L·ªói g·ªçi API: {e}")
                return []

        product_distances = {}

        for item in image_data["data"]:
            try:
                image_id = item.get("imageId", "unknown")
                tool_id = item.get("toolId", "unknown")
                feature_vector_base64 = item.get("featureVector")

                if not feature_vector_base64:
                    logging.warning(f"‚ö†Ô∏è B·ªè qua ·∫£nh {image_id} v√¨ thi·∫øu featureVector")
                    continue

                feature_vector = self.base64_to_floats(feature_vector_base64)
                assert feature_vector.shape[0] == 768, f"Feature vector c√≥ k√≠ch th∆∞·ªõc sai: {feature_vector.shape[0]}"
                logging.debug(f"Vector t·ª´ API (toolId={tool_id}): {feature_vector[:5]}...") 
                distance = self.calculate_distance(query_vector, feature_vector)

                if tool_id not in product_distances:
                    product_distances[tool_id] = {"distances": [], "image_ids": []}

                product_distances[tool_id]["distances"].append(distance)
                product_distances[tool_id]["image_ids"].append(image_id)

                logging.debug(f"üìå ImageId: {image_id}, ToolId: {tool_id}, Distance: {distance}")
                logging.debug("-" * 50)
            except Exception as e:
                logging.error(f"‚ùå L·ªói x·ª≠ l√Ω ·∫£nh {item.get('imageId', 'unknown')}: {e}")

        results = []

        for tool_id, data in product_distances.items():
            try:
                distances = data.get("distances", [])
                avg_distance = float(np.mean(distances)) if distances else float('inf')

                results.append({
                    "toolId": tool_id,
                    "avgDistance": avg_distance,
                    "imageIds": data.get("image_ids", [])
                })
            except Exception as e:  
                logging.error(f"‚ùå L·ªói t√≠nh to√°n avgDistance cho toolId={tool_id}: {e}")

        results.sort(key=lambda x: x["avgDistance"])

        return results
